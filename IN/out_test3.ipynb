{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bfb5d7c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [17]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121ff741-0401-47f2-842c-e1919f63d8f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:10.791716Z",
     "iopub.status.busy": "2024-04-10T12:54:10.791391Z",
     "iopub.status.idle": "2024-04-10T12:54:24.324418Z",
     "shell.execute_reply": "2024-04-10T12:54:24.323222Z"
    },
    "papermill": {
     "duration": 13.544192,
     "end_time": "2024-04-10T12:54:24.327114",
     "exception": false,
     "start_time": "2024-04-10T12:54:10.782922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from graph import load_graphs, SparseGraph, graph_from_sparse,construct_graphs,feature_names,load_graph_combined\n",
    "from model import SegmentClassifier\n",
    "from estimator import Estimator\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8100fdd-2f7e-4322-8df5-9bd0eb1cec99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.342098Z",
     "iopub.status.busy": "2024-04-10T12:54:24.341762Z",
     "iopub.status.idle": "2024-04-10T12:54:24.346556Z",
     "shell.execute_reply": "2024-04-10T12:54:24.345772Z"
    },
    "papermill": {
     "duration": 0.012918,
     "end_time": "2024-04-10T12:54:24.348376",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.335458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda=True\n",
    "if cuda:\n",
    "    np_to_torch = lambda x, volatile=False: (\n",
    "        torch.tensor(x.astype(np.float32), requires_grad=False).cuda())\n",
    "else:\n",
    "    np_to_torch = lambda x, volatile=False: (\n",
    "        torch.tensor(x.astype(np.float32), requires_grad=False))\n",
    "\n",
    "torch_to_np = lambda x: x.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1e1f44-6e03-4c8b-ae8a-8b55974a7a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.360368Z",
     "iopub.status.busy": "2024-04-10T12:54:24.359786Z",
     "iopub.status.idle": "2024-04-10T12:54:24.367062Z",
     "shell.execute_reply": "2024-04-10T12:54:24.366435Z"
    },
    "papermill": {
     "duration": 0.015018,
     "end_time": "2024-04-10T12:54:24.368643",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.353625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "def merge_graphs(graphs):\n",
    "    batch_size = len(graphs)\n",
    "    \n",
    "    # Special handling of batch size 1\n",
    "    if batch_size == 1:\n",
    "        g = graphs[0]\n",
    "        # Prepend singleton batch dimension\n",
    "        return g.X[None], g.Ri[None], g.Ro[None], g.y[None]\n",
    "    \n",
    "    # Get the maximum sizes in this batch\n",
    "    n_features = graphs[0].X.shape[1]\n",
    "    n_nodes = np.array([g.X.shape[0] for g in graphs])\n",
    "    n_edges = np.array([g.y.shape[0] for g in graphs])\n",
    "    max_nodes = n_nodes.max()\n",
    "    max_edges = n_edges.max()\n",
    "\n",
    "    # Allocate the tensors for this batch\n",
    "    batch_X = np.zeros((batch_size, max_nodes, n_features), dtype=np.float32)\n",
    "    batch_Ri = np.zeros((batch_size, max_nodes, max_edges), dtype=np.uint8)\n",
    "    batch_Ro = np.zeros((batch_size, max_nodes, max_edges), dtype=np.uint8)\n",
    "    batch_y = np.zeros((batch_size, max_edges), dtype=np.uint8)\n",
    "\n",
    "    # Loop over samples and fill the tensors\n",
    "    for i, g in enumerate(graphs):\n",
    "        batch_X[i, :n_nodes[i]] = g.X\n",
    "        batch_Ri[i, :n_nodes[i], :n_edges[i]] = g.Ri\n",
    "        batch_Ro[i, :n_nodes[i], :n_edges[i]] = g.Ro\n",
    "        batch_y[i, :n_edges[i]] = g.y\n",
    "    \n",
    "    return batch_X, batch_Ri, batch_Ro, batch_y\n",
    "\n",
    "def batch_generator(graphs, n_samples=1, batch_size=1, train=True):\n",
    "    volatile = not train\n",
    "    batch_idxs = np.arange(0, n_samples, batch_size)\n",
    "    # Loop over epochs\n",
    "    while True:\n",
    "        # Loop over batches\n",
    "        for j in batch_idxs:\n",
    "            #print('batch', j, '-', j+batch_size)\n",
    "            batch_graphs = [(g) for g in graphs[j:j+batch_size]]\n",
    "            batch_X, batch_Ri, batch_Ro, batch_y = merge_graphs(batch_graphs)\n",
    "            #print('  graphs merged')\n",
    "            batch_inputs = [\n",
    "                # torch.from_numpy(batch_X).cuda(),\n",
    "                # torch.from_numpy(batch_Ri).cuda(),\n",
    "                # torch.from_numpy(batch_Ro).cuda()\n",
    "                np_to_torch(batch_X, volatile=volatile),\n",
    "                np_to_torch(batch_Ri, volatile=volatile),\n",
    "                np_to_torch(batch_Ro, volatile=volatile)\n",
    "            ]\n",
    "            batch_target = np_to_torch(batch_y, volatile=volatile)\n",
    "            # batch_target=torch.from_numpy(batch_y).cuda()\n",
    "            #print('  data prepared')\n",
    "            yield batch_inputs, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc72ae4-c90a-45fd-871d-3ceaef240560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.380737Z",
     "iopub.status.busy": "2024-04-10T12:54:24.380294Z",
     "iopub.status.idle": "2024-04-10T12:54:24.383688Z",
     "shell.execute_reply": "2024-04-10T12:54:24.382908Z"
    },
    "papermill": {
     "duration": 0.011133,
     "end_time": "2024-04-10T12:54:24.385352",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.374219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = \"/lustrehome/federicacuna/TB_Sept_2023_ml/Data/npz_file_IN/\"\n",
    "lista=os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812559b6-55b9-499e-8a81-021274666ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.396919Z",
     "iopub.status.busy": "2024-04-10T12:54:24.396663Z",
     "iopub.status.idle": "2024-04-10T12:54:24.399910Z",
     "shell.execute_reply": "2024-04-10T12:54:24.399287Z"
    },
    "papermill": {
     "duration": 0.010843,
     "end_time": "2024-04-10T12:54:24.401474",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.390631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = [os.path.join(folder_path, file) for file in lista if \".ipynb_checkpoint\" not in file  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709d4d4b-a767-46f8-91dc-6809fd811764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.413563Z",
     "iopub.status.busy": "2024-04-10T12:54:24.413043Z",
     "iopub.status.idle": "2024-04-10T12:54:24.415866Z",
     "shell.execute_reply": "2024-04-10T12:54:24.415235Z"
    },
    "papermill": {
     "duration": 0.010375,
     "end_time": "2024-04-10T12:54:24.417381",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.407006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphs=load_graphs(lista,folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1df57c-d29f-44b8-acf5-17cc3ecc5659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.428682Z",
     "iopub.status.busy": "2024-04-10T12:54:24.428119Z",
     "iopub.status.idle": "2024-04-10T12:54:24.431873Z",
     "shell.execute_reply": "2024-04-10T12:54:24.431194Z"
    },
    "papermill": {
     "duration": 0.01034,
     "end_time": "2024-04-10T12:54:24.433076",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.422736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_number_from_filename(filename):\n",
    "    return int(filename.split(\"_npz\")[1].split(\".npz\")[0])\n",
    "\n",
    "# Ordina i file basati sul numero compreso tra \"_npz\" e \".npz\" nel loro nome\n",
    "graph_data_sorted = sorted([os.path.join(folder_path, file) for file in graph], key=extract_number_from_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246a8355-14fc-49d9-9d8a-ccbf375eca25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T12:54:24.443305Z",
     "iopub.status.busy": "2024-04-10T12:54:24.442610Z",
     "iopub.status.idle": "2024-04-10T17:59:09.818242Z",
     "shell.execute_reply": "2024-04-10T17:59:09.817451Z"
    },
    "papermill": {
     "duration": 18285.396637,
     "end_time": "2024-04-10T17:59:09.834373",
     "exception": false,
     "start_time": "2024-04-10T12:54:24.437736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 3min 55s, sys: 16.6 s, total: 5h 4min 11s\n",
      "Wall time: 5h 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_for_train=[]\n",
    "# for i in graph_data_sorted:\n",
    "#     # print(i)\n",
    "#     data_for_train.extend(load_graph_combined(i))\n",
    "for i in range(100):#graph_data_sorted:\n",
    "    print(i)\n",
    "    i=graph_data_sorted[i]\n",
    "    data_for_train.extend(load_graph_combined(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67df4c5e-fa2d-42ee-8ee8-ada93a091b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:59:09.857678Z",
     "iopub.status.busy": "2024-04-10T17:59:09.857519Z",
     "iopub.status.idle": "2024-04-10T17:59:09.861005Z",
     "shell.execute_reply": "2024-04-10T17:59:09.860406Z"
    },
    "papermill": {
     "duration": 0.016832,
     "end_time": "2024-04-10T17:59:09.862291",
     "exception": false,
     "start_time": "2024-04-10T17:59:09.845459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphs=load_graph_combined('test_npz.npz')\n",
    "graphs=data_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f42acd-2d53-4251-9de2-454da09722ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:59:09.884818Z",
     "iopub.status.busy": "2024-04-10T17:59:09.884672Z",
     "iopub.status.idle": "2024-04-10T17:59:09.891733Z",
     "shell.execute_reply": "2024-04-10T17:59:09.891280Z"
    },
    "papermill": {
     "duration": 0.019889,
     "end_time": "2024-04-10T17:59:09.893020",
     "exception": false,
     "start_time": "2024-04-10T17:59:09.873131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418000, 138000, 138000, 694000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 64\n",
    "n_iters = 7\n",
    "n_samples=len(graphs)\n",
    "# Training config\n",
    "batch_size = 1000#32\n",
    "n_epochs = 100\n",
    "valid_frac = 0.2\n",
    "test_frac = 0.2\n",
    "# We round by batch_size to avoid partial batches\n",
    "n_test = int(n_samples * test_frac) // batch_size * batch_size\n",
    "n_valid = int(n_samples * valid_frac) // batch_size * batch_size\n",
    "n_train = (n_samples - n_valid - n_test) // batch_size * batch_size\n",
    "n_train_batches = n_train // batch_size\n",
    "n_valid_batches = n_valid // batch_size\n",
    "n_test_batches = n_test #// batch_size\n",
    "\n",
    "n_train, n_valid, n_test, n_train + n_valid + n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17a5dac-a637-4c41-b73f-6bdf2cbb0b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:59:09.916454Z",
     "iopub.status.busy": "2024-04-10T17:59:09.916191Z",
     "iopub.status.idle": "2024-04-10T17:59:10.244280Z",
     "shell.execute_reply": "2024-04-10T17:59:10.243633Z"
    },
    "papermill": {
     "duration": 0.341644,
     "end_time": "2024-04-10T17:59:10.245756",
     "exception": false,
     "start_time": "2024-04-10T17:59:09.904112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 418455\n",
      "Valid set size: 138000\n",
      "Test set size:  138000\n"
     ]
    }
   ],
   "source": [
    "# Partition the dataset\n",
    "train_graphs, test_graphs = train_test_split(graphs, test_size=n_test)\n",
    "train_graphs, valid_graphs = train_test_split(train_graphs, test_size=n_valid)\n",
    "\n",
    "print('Train set size:', len(train_graphs))\n",
    "print('Valid set size:', len(valid_graphs))\n",
    "print('Test set size: ', len(test_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59e1877-f63d-43ac-acc9-e7148107c021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:59:10.268989Z",
     "iopub.status.busy": "2024-04-10T17:59:10.268849Z",
     "iopub.status.idle": "2024-04-10T17:59:10.272043Z",
     "shell.execute_reply": "2024-04-10T17:59:10.271617Z"
    },
    "papermill": {
     "duration": 0.016321,
     "end_time": "2024-04-10T17:59:10.273352",
     "exception": false,
     "start_time": "2024-04-10T17:59:10.257031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the batch generators\n",
    "train_batcher = batch_generator(train_graphs, n_samples=n_train, batch_size=batch_size)\n",
    "valid_batcher = batch_generator(valid_graphs, n_samples=n_valid, batch_size=batch_size, train=False)\n",
    "test_batcher = batch_generator(test_graphs, n_samples=n_test, batch_size=1, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b54775a-1f56-4aa2-b354-2f6fc976d685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:59:10.292239Z",
     "iopub.status.busy": "2024-04-10T17:59:10.292009Z",
     "iopub.status.idle": "2024-04-10T17:59:11.398072Z",
     "shell.execute_reply": "2024-04-10T17:59:11.397440Z"
    },
    "papermill": {
     "duration": 1.114554,
     "end_time": "2024-04-10T17:59:11.399114",
     "exception": false,
     "start_time": "2024-04-10T17:59:10.284560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 17:59:11.395583 Model: \n",
      "SegmentClassifier(\n",
      "  (input_network): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (edge_network): EdgeNetwork(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=138, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (node_network): NodeNetwork(\n",
      "    (network): Sequential(\n",
      "      (0): Linear(in_features=207, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2024-04-10 17:59:11.395740 Parameters: 26817\n"
     ]
    }
   ],
   "source": [
    "model = SegmentClassifier(input_dim=5, hidden_dim=hidden_dim, n_iters=n_iters)\n",
    "loss_func = nn.functional.binary_cross_entropy\n",
    "estim = Estimator(model, loss_func=loss_func, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d274fc1b-f2f5-4796-86cc-5f04506affad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T17:59:11.414498Z",
     "iopub.status.busy": "2024-04-10T17:59:11.414271Z",
     "iopub.status.idle": "2024-04-10T18:59:47.486964Z",
     "shell.execute_reply": "2024-04-10T18:59:47.486131Z"
    },
    "papermill": {
     "duration": 3636.081365,
     "end_time": "2024-04-10T18:59:47.487975",
     "exception": false,
     "start_time": "2024-04-10T17:59:11.406610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 17:59:11.415160 Epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 17:59:41.968355   training loss 0.616 time 30.5531s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 0\n",
      "2024-04-10 17:59:48.206519   validate loss 0.535\n",
      "2024-04-10 17:59:48.206549 Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:00:17.861276   training loss 0.441 time 29.6547s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 1\n",
      "2024-04-10 18:00:23.674087   validate loss 0.346\n",
      "2024-04-10 18:00:23.674111 Epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:00:52.629320   training loss 0.268 time 28.9552s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 2\n",
      "2024-04-10 18:00:58.812559   validate loss 0.202\n",
      "2024-04-10 18:00:58.812591 Epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:01:28.406697   training loss 0.156 time 29.5941s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 3\n",
      "2024-04-10 18:01:34.505495   validate loss 0.12\n",
      "2024-04-10 18:01:34.505524 Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:02:04.409918   training loss 0.0973 time 29.9043s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 4\n",
      "2024-04-10 18:02:10.302802   validate loss 0.0801\n",
      "2024-04-10 18:02:10.302826 Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:02:40.466010   training loss 0.0662 time 30.1631s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 5\n",
      "2024-04-10 18:02:46.640542   validate loss 0.0567\n",
      "2024-04-10 18:02:46.640573 Epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:03:15.753431   training loss 0.0506 time 29.1128s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 6\n",
      "2024-04-10 18:03:21.732597   validate loss 0.045\n",
      "2024-04-10 18:03:21.732622 Epoch 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:03:51.770939   training loss 0.0406 time 30.0383s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 7\n",
      "2024-04-10 18:03:58.128837   validate loss 0.0371\n",
      "2024-04-10 18:03:58.128867 Epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:04:27.229960   training loss 0.035 time 29.101s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 8\n",
      "2024-04-10 18:04:33.516112   validate loss 0.0328\n",
      "2024-04-10 18:04:33.516140 Epoch 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:05:02.707416   training loss 0.0318 time 29.1912s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 9\n",
      "2024-04-10 18:05:08.566785   validate loss 0.0303\n",
      "2024-04-10 18:05:08.566819 Epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:05:39.129722   training loss 0.0287 time 30.5629s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 10\n",
      "2024-04-10 18:05:45.658008   validate loss 0.0278\n",
      "2024-04-10 18:05:45.658030 Epoch 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:06:16.502509   training loss 0.0269 time 30.8444s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 11\n",
      "2024-04-10 18:06:23.022788   validate loss 0.0264\n",
      "2024-04-10 18:06:23.022818 Epoch 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:06:53.515537   training loss 0.0253 time 30.4927s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 12\n",
      "2024-04-10 18:06:59.366966   validate loss 0.0249\n",
      "2024-04-10 18:06:59.366991 Epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:07:29.880108   training loss 0.0254 time 30.5131s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:07:35.811166   validate loss 0.042\n",
      "2024-04-10 18:07:35.811298 Epoch 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:08:06.452121   training loss 0.0288 time 30.6408s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 14\n",
      "2024-04-10 18:08:12.691761   validate loss 0.0246\n",
      "2024-04-10 18:08:12.691793 Epoch 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:08:43.101069   training loss 0.0245 time 30.4092s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 15\n",
      "2024-04-10 18:08:49.313225   validate loss 0.0243\n",
      "2024-04-10 18:08:49.313247 Epoch 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:09:19.057421   training loss 0.0233 time 29.7441s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 16\n",
      "2024-04-10 18:09:24.956966   validate loss 0.0232\n",
      "2024-04-10 18:09:24.956996 Epoch 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:09:55.794253   training loss 0.0227 time 30.8372s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 17\n",
      "2024-04-10 18:10:02.332717   validate loss 0.0224\n",
      "2024-04-10 18:10:02.332748 Epoch 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:10:32.962735   training loss 0.0219 time 30.6299s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 18\n",
      "2024-04-10 18:10:39.369712   validate loss 0.0221\n",
      "2024-04-10 18:10:39.369745 Epoch 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:11:10.428061   training loss 0.0224 time 31.0583s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 19\n",
      "2024-04-10 18:11:16.143920   validate loss 0.0216\n",
      "2024-04-10 18:11:16.143942 Epoch 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:11:45.481926   training loss 0.0212 time 29.3379s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 20\n",
      "2024-04-10 18:11:51.695809   validate loss 0.0213\n",
      "2024-04-10 18:11:51.695833 Epoch 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:12:21.320328   training loss 0.0227 time 29.6244s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:12:27.283468   validate loss 0.0229\n",
      "2024-04-10 18:12:27.283589 Epoch 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:12:57.664348   training loss 0.022 time 30.3807s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:13:03.481646   validate loss 0.0217\n",
      "2024-04-10 18:13:03.481779 Epoch 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:13:33.625552   training loss 0.0226 time 30.1437s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:13:39.811543   validate loss 0.0221\n",
      "2024-04-10 18:13:39.811866 Epoch 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:14:10.401283   training loss 0.0224 time 30.5894s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:14:16.523182   validate loss 0.0221\n",
      "2024-04-10 18:14:16.523310 Epoch 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:14:46.957086   training loss 0.0222 time 30.4337s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:14:52.735119   validate loss 0.0248\n",
      "2024-04-10 18:14:52.735330 Epoch 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:15:23.642422   training loss 0.0225 time 30.907s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:15:29.884259   validate loss 0.0216\n",
      "2024-04-10 18:15:29.884571 Epoch 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:15:59.245905   training loss 0.0202 time 29.3613s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 27\n",
      "2024-04-10 18:16:05.221469   validate loss 0.0202\n",
      "2024-04-10 18:16:05.221501 Epoch 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:16:35.471254   training loss 0.0242 time 30.2497s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:16:41.768273   validate loss 0.0243\n",
      "2024-04-10 18:16:41.768418 Epoch 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:17:12.235539   training loss 0.023 time 30.4671s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:17:18.110662   validate loss 0.0221\n",
      "2024-04-10 18:17:18.110783 Epoch 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:17:47.874954   training loss 0.0208 time 29.7641s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:17:54.287698   validate loss 0.0208\n",
      "2024-04-10 18:17:54.287937 Epoch 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:18:24.618986   training loss 0.0225 time 30.331s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:18:30.590943   validate loss 0.0224\n",
      "2024-04-10 18:18:30.591075 Epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:19:01.437854   training loss 0.0215 time 30.8467s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:19:07.330967   validate loss 0.0218\n",
      "2024-04-10 18:19:07.331117 Epoch 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:19:37.671421   training loss 0.0221 time 30.3403s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:19:43.766721   validate loss 0.0255\n",
      "2024-04-10 18:19:43.766998 Epoch 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:20:13.649031   training loss 0.0224 time 29.882s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:20:19.764337   validate loss 0.0221\n",
      "2024-04-10 18:20:19.764455 Epoch 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:20:50.502870   training loss 0.0211 time 30.7384s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:20:56.480886   validate loss 0.0213\n",
      "2024-04-10 18:20:56.481022 Epoch 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:21:26.684357   training loss 0.0204 time 30.2033s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 36\n",
      "2024-04-10 18:21:32.846366   validate loss 0.0201\n",
      "2024-04-10 18:21:32.846397 Epoch 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:22:03.156903   training loss 0.0222 time 30.3105s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:22:09.264596   validate loss 0.0221\n",
      "2024-04-10 18:22:09.264738 Epoch 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:22:38.504470   training loss 0.0217 time 29.2397s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:22:44.477174   validate loss 0.0218\n",
      "2024-04-10 18:22:44.477389 Epoch 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:23:14.384827   training loss 0.0245 time 29.9074s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:23:20.521670   validate loss 0.0279\n",
      "2024-04-10 18:23:20.521790 Epoch 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:23:50.163553   training loss 0.0222 time 29.6417s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:23:56.192389   validate loss 0.0208\n",
      "2024-04-10 18:23:56.192627 Epoch 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:24:25.504442   training loss 0.0219 time 29.3118s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:24:31.638759   validate loss 0.022\n",
      "2024-04-10 18:24:31.638894 Epoch 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:25:02.036156   training loss 0.0223 time 30.3972s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:25:08.305218   validate loss 0.0215\n",
      "2024-04-10 18:25:08.305502 Epoch 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:25:38.436228   training loss 0.0221 time 30.1307s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:25:44.553516   validate loss 0.022\n",
      "2024-04-10 18:25:44.553832 Epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:26:14.810247   training loss 0.0221 time 30.2564s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:26:20.816801   validate loss 0.0217\n",
      "2024-04-10 18:26:20.817068 Epoch 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:26:51.415022   training loss 0.0213 time 30.5979s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:26:57.790628   validate loss 0.0215\n",
      "2024-04-10 18:26:57.790937 Epoch 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:27:28.095350   training loss 0.021 time 30.3044s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:27:34.248113   validate loss 0.0215\n",
      "2024-04-10 18:27:34.248420 Epoch 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:28:04.638943   training loss 0.0211 time 30.3905s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:28:10.535269   validate loss 0.0212\n",
      "2024-04-10 18:28:10.535553 Epoch 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:28:41.008683   training loss 0.0213 time 30.4731s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:28:47.171600   validate loss 0.0227\n",
      "2024-04-10 18:28:47.171726 Epoch 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:29:17.900720   training loss 0.0283 time 30.7289s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:29:24.107486   validate loss 0.0294\n",
      "2024-04-10 18:29:24.107620 Epoch 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:29:54.711664   training loss 0.0269 time 30.604s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:30:01.035454   validate loss 0.0266\n",
      "2024-04-10 18:30:01.035749 Epoch 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:30:30.911833   training loss 0.0255 time 29.876s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:30:37.288547   validate loss 0.0255\n",
      "2024-04-10 18:30:37.288777 Epoch 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:31:07.716082   training loss 0.0247 time 30.4272s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:31:13.774299   validate loss 0.0249\n",
      "2024-04-10 18:31:13.774429 Epoch 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:31:43.155663   training loss 0.0243 time 29.3812s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:31:49.662602   validate loss 0.0244\n",
      "2024-04-10 18:31:49.662889 Epoch 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:32:20.581758   training loss 0.0231 time 30.9188s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:32:27.039208   validate loss 0.0231\n",
      "2024-04-10 18:32:27.039510 Epoch 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:32:56.373594   training loss 0.0225 time 29.334s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:33:02.242019   validate loss 0.0228\n",
      "2024-04-10 18:33:02.242152 Epoch 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:33:33.073293   training loss 0.0222 time 30.8311s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:33:39.306312   validate loss 0.0225\n",
      "2024-04-10 18:33:39.306440 Epoch 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:34:08.756922   training loss 0.0224 time 29.4504s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:34:14.598873   validate loss 0.0232\n",
      "2024-04-10 18:34:14.599175 Epoch 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:34:45.549089   training loss 0.0224 time 30.9499s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:34:51.887496   validate loss 0.0222\n",
      "2024-04-10 18:34:51.887769 Epoch 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:35:21.967225   training loss 0.0218 time 30.0794s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:35:27.825839   validate loss 0.022\n",
      "2024-04-10 18:35:27.826102 Epoch 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:35:58.594417   training loss 0.0217 time 30.7683s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:36:04.893021   validate loss 0.0219\n",
      "2024-04-10 18:36:04.893257 Epoch 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:36:35.226029   training loss 0.0216 time 30.3327s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:36:41.381954   validate loss 0.0218\n",
      "2024-04-10 18:36:41.382068 Epoch 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:37:11.471708   training loss 0.022 time 30.0896s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:37:17.716227   validate loss 0.0218\n",
      "2024-04-10 18:37:17.716895 Epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:37:48.859236   training loss 0.0217 time 31.1423s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:37:54.472264   validate loss 0.0234\n",
      "2024-04-10 18:37:54.472413 Epoch 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:38:25.340285   training loss 0.022 time 30.8676s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:38:31.853492   validate loss 0.0222\n",
      "2024-04-10 18:38:31.853773 Epoch 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:39:03.007633   training loss 0.0213 time 31.1538s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:39:09.023848   validate loss 0.0206\n",
      "2024-04-10 18:39:09.024103 Epoch 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:39:39.393683   training loss 0.021 time 30.3695s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:39:45.383205   validate loss 0.0211\n",
      "2024-04-10 18:39:45.383445 Epoch 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:40:15.968786   training loss 0.0207 time 30.5853s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:40:22.414269   validate loss 0.0208\n",
      "2024-04-10 18:40:22.414544 Epoch 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:40:52.966209   training loss 0.0245 time 30.5516s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:40:59.021970   validate loss 0.022\n",
      "2024-04-10 18:40:59.022250 Epoch 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:41:28.816452   training loss 0.0204 time 29.7942s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:41:35.146098   validate loss 0.0205\n",
      "2024-04-10 18:41:35.146317 Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:42:05.672927   training loss 0.0211 time 30.5266s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:42:11.995655   validate loss 0.0275\n",
      "2024-04-10 18:42:11.995932 Epoch 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:42:42.541551   training loss 0.0247 time 30.5456s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:42:48.777450   validate loss 0.0244\n",
      "2024-04-10 18:42:48.777709 Epoch 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:43:18.451626   training loss 0.0239 time 29.6739s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:43:24.623485   validate loss 0.0238\n",
      "2024-04-10 18:43:24.623614 Epoch 73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:43:55.328421   training loss 0.0236 time 30.7048s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:44:01.840430   validate loss 0.023\n",
      "2024-04-10 18:44:01.840705 Epoch 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:44:32.163343   training loss 0.0224 time 30.3226s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:44:38.559650   validate loss 0.0227\n",
      "2024-04-10 18:44:38.559921 Epoch 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:45:08.440092   training loss 0.0222 time 29.8801s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:45:14.701851   validate loss 0.0224\n",
      "2024-04-10 18:45:14.701966 Epoch 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:45:43.583711   training loss 0.022 time 28.8817s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:45:49.390273   validate loss 0.0226\n",
      "2024-04-10 18:45:49.390454 Epoch 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:46:19.257186   training loss 0.0223 time 29.8667s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:46:25.352993   validate loss 0.0241\n",
      "2024-04-10 18:46:25.353309 Epoch 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:46:56.103907   training loss 0.0229 time 30.7506s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:47:02.701120   validate loss 0.0232\n",
      "2024-04-10 18:47:02.701372 Epoch 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:47:33.250447   training loss 0.0219 time 30.549s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:47:39.566260   validate loss 0.022\n",
      "2024-04-10 18:47:39.566536 Epoch 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:48:09.732735   training loss 0.0218 time 30.1662s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:48:15.856731   validate loss 0.0247\n",
      "2024-04-10 18:48:15.856854 Epoch 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:48:46.126566   training loss 0.023 time 30.2697s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:48:52.167994   validate loss 0.023\n",
      "2024-04-10 18:48:52.168251 Epoch 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:49:22.319393   training loss 0.0226 time 30.1511s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:49:28.222166   validate loss 0.0226\n",
      "2024-04-10 18:49:28.222456 Epoch 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:49:59.062526   training loss 0.0224 time 30.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:50:05.446266   validate loss 0.024\n",
      "2024-04-10 18:50:05.446468 Epoch 84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:50:35.137908   training loss 0.0225 time 29.6914s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:50:41.335808   validate loss 0.022\n",
      "2024-04-10 18:50:41.335946 Epoch 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:51:11.982362   training loss 0.0215 time 30.6464s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:51:18.425403   validate loss 0.0215\n",
      "2024-04-10 18:51:18.425672 Epoch 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:51:48.645298   training loss 0.0218 time 30.2196s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:51:54.637129   validate loss 0.0218\n",
      "2024-04-10 18:51:54.637372 Epoch 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:52:23.767103   training loss 0.0211 time 29.1297s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:52:29.794248   validate loss 0.0214\n",
      "2024-04-10 18:52:29.794393 Epoch 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:53:00.870392   training loss 0.0209 time 31.076s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:53:07.029856   validate loss 0.0209\n",
      "2024-04-10 18:53:07.030128 Epoch 89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:53:36.808198   training loss 0.0206 time 29.778s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:53:42.952861   validate loss 0.021\n",
      "2024-04-10 18:53:42.953121 Epoch 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:54:13.426253   training loss 0.0208 time 30.4731s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:54:19.548447   validate loss 0.0211\n",
      "2024-04-10 18:54:19.548691 Epoch 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:54:50.310122   training loss 0.0214 time 30.7614s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:54:56.256087   validate loss 0.0224\n",
      "2024-04-10 18:54:56.256212 Epoch 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:55:25.870711   training loss 0.0209 time 29.6144s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:55:32.231906   validate loss 0.0209\n",
      "2024-04-10 18:55:32.232154 Epoch 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:56:02.677339   training loss 0.0213 time 30.4451s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:56:08.449618   validate loss 0.0217\n",
      "2024-04-10 18:56:08.449766 Epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:56:38.800469   training loss 0.0208 time 30.3507s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:56:45.158127   validate loss 0.0218\n",
      "2024-04-10 18:56:45.158357 Epoch 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:57:14.932752   training loss 0.0212 time 29.7743s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:57:21.203987   validate loss 0.0221\n",
      "2024-04-10 18:57:21.204291 Epoch 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:57:51.282610   training loss 0.0256 time 30.0783s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:57:57.598102   validate loss 0.0243\n",
      "2024-04-10 18:57:57.598363 Epoch 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:58:28.347220   training loss 0.0235 time 30.7488s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:58:34.724928   validate loss 0.024\n",
      "2024-04-10 18:58:34.725176 Epoch 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:59:05.012326   training loss 0.0228 time 30.2871s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:59:11.074951   validate loss 0.0227\n",
      "2024-04-10 18:59:11.075208 Epoch 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:59:41.017378   training loss 0.0222 time 29.9421s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-10 18:59:47.483008   validate loss 0.0228\n"
     ]
    }
   ],
   "source": [
    "estim.fit_gen(train_batcher, n_batches=n_train_batches, n_epochs=100,\n",
    "              valid_generator=valid_batcher, n_valid_batches=n_valid_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37aee8a5-90c3-4a5a-97d4-abcae1805e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:59:47.521478Z",
     "iopub.status.busy": "2024-04-10T18:59:47.520798Z",
     "iopub.status.idle": "2024-04-10T18:59:47.685769Z",
     "shell.execute_reply": "2024-04-10T18:59:47.685106Z"
    },
    "papermill": {
     "duration": 0.18131,
     "end_time": "2024-04-10T18:59:47.686740",
     "exception": false,
     "start_time": "2024-04-10T18:59:47.505430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "plt.figure()\n",
    "plt.plot(estim.train_losses, label='training set')\n",
    "plt.plot(estim.valid_losses, label='validation set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f3b409-a216-4d55-a8c6-a09827b62920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:59:47.718076Z",
     "iopub.status.busy": "2024-04-10T18:59:47.717910Z",
     "iopub.status.idle": "2024-04-10T18:59:47.721655Z",
     "shell.execute_reply": "2024-04-10T18:59:47.721184Z"
    },
    "papermill": {
     "duration": 0.020339,
     "end_time": "2024-04-10T18:59:47.722551",
     "exception": false,
     "start_time": "2024-04-10T18:59:47.702212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550de44",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2db7be8-b0e6-4b02-b7e6-8d0f6f4ee714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:59:47.753143Z",
     "iopub.status.busy": "2024-04-10T18:59:47.752585Z",
     "iopub.status.idle": "2024-04-10T19:08:12.799631Z",
     "shell.execute_reply": "2024-04-10T19:08:12.798664Z"
    },
    "papermill": {
     "duration": 505.099593,
     "end_time": "2024-04-10T19:08:12.836927",
     "exception": true,
     "start_time": "2024-04-10T18:59:47.737334",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 2.25 MiB is free. Process 30267 has 664.00 MiB memory in use. Process 49283 has 19.27 GiB memory in use. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 64.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_batcher \u001b[38;5;241m=\u001b[39m batch_generator(test_graphs, n_samples\u001b[38;5;241m=\u001b[39mn_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m test_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mestim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_batcher\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model_IN.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_test_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m [torch_to_np(o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m test_outputs]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Flatten the predictions and labels\u001b[39;00m\n",
      "File \u001b[0;32m~/TB_Sept_2023_ml/Code/IN/estimator.py:97\u001b[0m, in \u001b[0;36mEstimator.predict\u001b[0;34m(self, generator, model_name, n_batches, concat)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[1;32m     96\u001b[0m     test_input, test_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(generator)\n\u001b[0;32m---> 97\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat:\n\u001b[1;32m     99\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/TB_Sept_2023_ml/Code/IN/model.py:83\u001b[0m, in \u001b[0;36mSegmentClassifier.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     81\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_network(H, Ri, Ro)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Apply node network\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Shortcut connect the inputs onto the hidden representation\u001b[39;00m\n\u001b[1;32m     85\u001b[0m H \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([H, X], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/TB_Sept_2023_ml/Code/IN/model.py:52\u001b[0m, in \u001b[0;36mNodeNetwork.forward\u001b[0;34m(self, X, e, Ri, Ro)\u001b[0m\n\u001b[1;32m     50\u001b[0m mo \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(Rwo, bi)\n\u001b[1;32m     51\u001b[0m M \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([mi, mo, X], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 2.25 MiB is free. Process 30267 has 664.00 MiB memory in use. Process 49283 has 19.27 GiB memory in use. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 64.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "test_batcher = batch_generator(test_graphs, n_samples=n_test, batch_size=1, train=False)\n",
    "test_outputs = estim.predict(test_batcher,'best_model_IN.pkl', n_test_batches, concat=False)\n",
    "test_preds = [torch_to_np(o) for o in test_outputs]\n",
    "\n",
    "# Flatten the predictions and labels\n",
    "flat_y = np.concatenate([g.y.flatten() for g in test_graphs])\n",
    "flat_pred = np.concatenate([p.flatten() for p in test_preds])\n",
    "thresh = 0.8\n",
    "print('Test set results with threshold of', thresh)\n",
    "print('Accuracy:  %.4f' % sklearn.metrics.accuracy_score(flat_y, flat_pred>thresh))\n",
    "print('Precision: %.4f' % sklearn.metrics.precision_score(flat_y, flat_pred>thresh))\n",
    "print('Recall:    %.4f' % sklearn.metrics.recall_score(flat_y, flat_pred>thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e67bc-dcbf-4ed6-b226-4cf0cbc36a8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = sklearn.metrics.roc_curve(flat_y, flat_pred)\n",
    "plt.figure(figsize=(9,4))\n",
    "\n",
    "# Plot the model outputs\n",
    "plt.subplot(121)\n",
    "binning=dict(bins=50, range=(0,1), histtype='bar')\n",
    "plt.hist(flat_pred[flat_y<0.5], label='fake', **binning)\n",
    "plt.hist(flat_pred[flat_y>0.5], label='true', **binning)\n",
    "plt.xlabel('Model output')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.subplot(122)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], '--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e26ee-646d-44bc-8fc6-30a2e5ee0ce3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_sample(X, Ri, Ro, y, cmap='bwr_r', alpha_labels=False):\n",
    "    # Select the i/o node features for each segment\n",
    "    feats_o = X[np.where(Ri.T)[1]]\n",
    "    feats_i = X[np.where(Ro.T)[1]]\n",
    "    # Prepare the figure\n",
    "    fig, ax0 = plt.subplots(figsize=(9,4))\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "\n",
    "    ax0.scatter(X[:,2], X[:,1], c='k')\n",
    "    \n",
    "    # Draw the segments\n",
    "    for j in range(y.shape[0]):\n",
    "        if alpha_labels:\n",
    "            seg_args = dict(c='b', alpha=float(y[j]))\n",
    "        else:\n",
    "            seg_args = dict(c=cmap(float(y[j])))\n",
    "        ax0.plot([feats_o[j,2], feats_i[j,2]],\n",
    "                 [feats_o[j,1], feats_i[j,1]], '-', **seg_args)\n",
    "    \n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    sm.set_array(y)\n",
    "    cbar = plt.colorbar(sm, ax=ax0)\n",
    "    cbar.set_label('Colorbar Label')  # Set the label for the colorbar\n",
    "    \n",
    "    # Adjust axes\n",
    "    ax0.set_xlabel('zx_hit [mm]')\n",
    "    ax0.set_ylabel('x_hit ')\n",
    "    ax0.set_xlim(-100,2000)\n",
    "    ax0.set_ylim(-20,20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d65905-3605-4b24-b79d-04a8525aebae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    g = (test_graphs[i])\n",
    "    pred = test_preds[i].squeeze(0)\n",
    "    print(pred)\n",
    "    print('accuracy %.3f, precision %.3f, recall %.3f' % (\n",
    "        sklearn.metrics.accuracy_score(g.y, pred>thresh),\n",
    "        sklearn.metrics.precision_score(g.y, pred>thresh),\n",
    "        sklearn.metrics.recall_score(g.y, pred>thresh)))\n",
    "    draw_sample(g.X, g.Ri, g.Ro, pred, alpha_labels=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8906f-ef04-406f-9278-5df148958982",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccc4e7-e0d5-4677-86a7-bd7479e9e09b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22448.204188,
   "end_time": "2024-04-10T19:08:18.218859",
   "environment_variables": {},
   "exception": true,
   "input_path": "Model.ipynb",
   "output_path": "out_test3.ipynb",
   "parameters": {},
   "start_time": "2024-04-10T12:54:10.014671",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}