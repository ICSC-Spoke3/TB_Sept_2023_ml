{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1d4eb53-381d-461b-8265-c8419714ac54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arm-mango in /home/federicacuna/.local/lib/python3.11/site-packages (1.4.3)\n",
      "Requirement already satisfied: attrdict>=2.0.1 in /home/federicacuna/.local/lib/python3.11/site-packages (from arm-mango) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/miniconda3/lib/python3.11/site-packages (from arm-mango) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>=0.21.3 in /home/federicacuna/.local/lib/python3.11/site-packages (from arm-mango) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/federicacuna/.local/lib/python3.11/site-packages (from arm-mango) (1.13.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/miniconda3/lib/python3.11/site-packages (from arm-mango) (4.65.0)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.11/site-packages (from attrdict>=2.0.1->arm-mango) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/federicacuna/.local/lib/python3.11/site-packages (from scikit_learn>=0.21.3->arm-mango) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/federicacuna/.local/lib/python3.11/site-packages (from scikit_learn>=0.21.3->arm-mango) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arm-mango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29bda30-8b55-4e51-9276-2992b667a6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd13ce4-797f-48bf-80ac-1c78bbc5a7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mango import Tuner\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83754e1-bc04-4dda-bf89-85feec3a98dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_dir = os.path.abspath(\"/lustrehome/federicacuna/TB_Sept_2023_ml/Code/Pytorch_gnn/\")\n",
    "sys.path.append(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdf0a41-fc2d-4ff9-90b5-36c680240c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import time\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os\n",
    "from torch_geometric.nn import Sequential, GCNConv,GATConv\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import time\n",
    "import MyData as data\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import GNN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72dd1b0b-7f9b-4fee-8a7d-17ed9c7509dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    # def __init__(self, hidden_size, num_ly, num_feat, num_class,num_to_reduce):\n",
    "    def __init__(self, num_feat, hidden_size,num_class, model_params):\n",
    "        super().__init__()\n",
    "        num_ly_val = model_params[\"model_num_ly\"]\n",
    "        num_to_reduce=model_params[\"model_num_toreduce\"]\n",
    "        aggr=model_params[\"model_aggr\"]\n",
    "        for num_ly in range( num_ly_val):\n",
    "            if(hidden_size - (num_ly - 1) * num_ly==0):\n",
    "                print('not proper number of ly and hidden size')\n",
    "                num_ly=int(hidden_size/num)\n",
    "                print(f' the number of layer will be set to: {num_ly}')\n",
    "            \n",
    "            # return\n",
    "        # Model layers\n",
    "        self.num_ly = num_ly\n",
    "        self.conv_layers = torch.nn.ModuleList()\n",
    "        \n",
    "        self.conv_layers.append(GCNConv(num_feat, hidden_size,aggr))\n",
    "        \n",
    "        for i in range(1, num_ly):\n",
    "            current_hidden_size = hidden_size - i * num_to_reduce\n",
    "            prev_hidden_size = hidden_size - (i - 1) * num_to_reduce\n",
    "            self.conv_layers.append(GCNConv(prev_hidden_size, current_hidden_size,aggr))\n",
    "\n",
    "        self.conv_layers.append(GCNConv(hidden_size - (num_ly - 1) * num_to_reduce, num_class))\n",
    "\n",
    "    def forward(self, data):\n",
    "    \n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        for conv in self.conv_layers[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.tanh(x)\n",
    "            # x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_layers[-1](x, edge_index)\n",
    "        \n",
    "        return F.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40bd524-63c6-4823-9e7f-234fd530b609",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA A100-PCIE-40GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e92d754-abbb-4a72-98f7-fe467b6b912b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# NUM_FEATURES = train_dataset[0].x.shape[1]\n",
    "# print(NUM_FEATURES)\n",
    "# NUM_CLASSES =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dae7e86-297f-477d-94a6-216461ae56e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in train_loader:\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        model_output=model(batch)\n",
    "        # Passing the node features and the connection info\n",
    "        pred = torch.where(model_output > 0.8, 1, 0)\n",
    "        # Calculating the loss and gradients\n",
    "        labels=batch.y.float().to(device)\n",
    "        loss = loss_fn(model_output.squeeze(1).float(), labels)  # Compute the loss.\n",
    "\n",
    "        # loss = criterion(out.squeeze(1).float(), labels)\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3162567-e391-44ec-90ed-d36e8adb562f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    all_preds = []\n",
    "    all_preds_raw = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)  \n",
    "        model_output=model(batch)\n",
    "        pred = torch.where(model_output > 0.8, 1, 0)\n",
    "        # pred = model(batch.x.float(), \n",
    "        #                 batch.edge_index, \n",
    "        #                 batch.batch) \n",
    "        # loss = loss_fn(torch.squeeze(pred), batch.y.long().to(device))\n",
    "        \n",
    "        labels=batch.y.float().to(device)\n",
    "        loss = loss_fn(model_output.squeeze(1).float(), labels)  # Compute the loss.\n",
    "\n",
    "\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_preds_raw.append(torch.sigmoid(pred).cpu().detach().numpy())\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    # log_conf_matrix(all_preds, all_labels, epoch)\n",
    "    return running_loss/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc2cc35-0805-4464-8de7-1f8b14524fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mango import scheduler\n",
    "\n",
    "def run_one_training(params):\n",
    "    params = params[0]\n",
    "    \n",
    "\n",
    "    data_handler=data.dataset_preparation(root='/lustrehome/federicacuna/TB_Sept_2023_ml/Data/preprocessed')\n",
    "    fnamex='pi-_10GeV_4ly_1e-4ly_normalized_1e-4_viewx'\n",
    "    fnamey='pi-_10GeV_4ly_1e-4ly_normalized_1e-4_viewy'\n",
    "    data_trk=data_handler.get_more_file(0,50,fnamex)+data_handler.get_more_file(0,50,fnamey)\n",
    "    data_val=data_handler.get_more_file(600,605,fnamex)+data_handler.get_more_file(600,605,fnamey)\n",
    "    data_handler2=data.dataset_preparation(root='/lustrehome/federicacuna/TB_Sept_2023_ml/Data/preprocessed')\n",
    "    fnameHNx='pi-_10GeV_4ly_3e-4ly_normalized_viewx'\n",
    "    fnameHNy='pi-_10GeV_4ly_3e-4ly_normalized_viewy'\n",
    "    dataHN=data_handler2.get_more_file(0,50,fnameHNx)+data_handler2.get_more_file(0,50,fnameHNy)\n",
    "    dataHN_val=data_handler2.get_more_file(600,605,fnameHNx)+data_handler2.get_more_file(600,605,fnameHNy)\n",
    "    # Prepare training\n",
    "    train_dataset=dataHN+data_trk\n",
    "    val_dataset=data_val+dataHN_val\n",
    "    test_dataset=val_dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    # Loading the model\n",
    "    print(\"Loading model...\")\n",
    "    model_params = {k: v for k, v in params.items() if k.startswith(\"model_\")}\n",
    "    # print(model_params)\n",
    "    hidden_size = model_params['model_num_toreduce'] * model_params['model_num_ly']\n",
    "    model = GCN(5, hidden_size, 1, model_params) \n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    # < 1 increases precision, > 1 recall\n",
    "    # weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "    # loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "    loss_fn=torch.nn.functional.binary_cross_entropy#for sageconv\n",
    "    # loss = criterion(out.squeeze(1).float(), labels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), \n",
    "    #                             lr=params[\"learning_rate\"],\n",
    "    #                             momentum=params[\"sgd_momentum\"],\n",
    "    #                             weight_decay=params[\"weight_decay\"])\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=params[\"scheduler_gamma\"])\n",
    "    \n",
    "    # Start training\n",
    "    best_loss = 1000\n",
    "    early_stopping_counter = 0\n",
    "    for epoch in range(1,1500): \n",
    "        if early_stopping_counter <= 10: # = x * 5 \n",
    "            # Training\n",
    "            model.train()\n",
    "            loss = train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n",
    "            print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "            \n",
    "\n",
    "            # Testing\n",
    "            model.eval()\n",
    "            if epoch % 10 == 0:\n",
    "                loss = test(epoch, model, test_loader, loss_fn)\n",
    "                print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
    "                           \n",
    "                # Update best loss\n",
    "                if float(loss) < best_loss:\n",
    "                    best_loss = loss\n",
    "                    # Save the currently best model \n",
    "                    torch.save(model, f'/lustrehome/federicacuna/TB_Sept_2023_ml/output_gnn_pkl/hyp_gcnconv.pkl')\n",
    "                    early_stopping_counter = 0\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "            # scheduler.step()\n",
    "        else:\n",
    "            print(\"Early stopping due to no improvement.\")\n",
    "            return [best_loss]\n",
    "    print(f\"Finishing training with best test loss: {best_loss}\")\n",
    "    return [best_loss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e536def0-38f9-48bb-8a9e-bf4dff44c633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    \"batch_size\": [4032],\n",
    "    \"model_num_toreduce\": [64],\n",
    "    \"model_num_ly\":[5,7,10],\n",
    "    \"lr\":[5e-5],\n",
    "    \"model_aggr\":['sum','mean','max']\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa431d2-212f-46fb-8b83-824dd9785dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_conf_matrix(y_pred, y_true, epoch):\n",
    "    # Log confusion matrix as image\n",
    "    cm = confusion_matrix(y_pred, y_true,normalize='all')\n",
    "    classes = [\"0\", \"1\"]\n",
    "    df_cfm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    cfm_plot = sns.heatmap(df_cfm, annot=True, cmap='Blues', fmt='g')\n",
    "    # cfm_plot.figure.savefig(f'cm_{epoch}.png')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb438599-e4eb-411f-acb2-227862b0bad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "   \n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_pred)\n",
    "        print(f\"ROC AUC: {roc}\")\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(f\"ROC AUC: notdefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2999312e-e63e-4131-9896-d8ef75e16c13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparameter search...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_one_training() got an unexpected keyword argument 'model_num_toreduce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      7\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(HYPERPARAMETERS,\n\u001b[1;32m      8\u001b[0m               objective\u001b[38;5;241m=\u001b[39mrun_one_training,\n\u001b[1;32m      9\u001b[0m               conf_dict\u001b[38;5;241m=\u001b[39mconfig) \n\u001b[0;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:160\u001b[0m, in \u001b[0;36mTuner.minimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize_objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:147\u001b[0m, in \u001b[0;36mTuner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_bayesian:\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunBayesianOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_random:\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunRandomOptimizer()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:210\u001b[0m, in \u001b[0;36mTuner.runBayesianOptimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunBayesianOptimizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    208\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 210\u001b[0m     X_list, Y_list, X_tried \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# evaluated hyper parameters are used\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     X_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mconvert_GP_space(X_list)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:187\u001b[0m, in \u001b[0;36mTuner.run_initial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# getting first few random values\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     X_tried \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mget_random_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39minitial_random)\n\u001b[0;32m--> 187\u001b[0m     X_list, Y_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunUserObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tried\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# in case initial random results are invalid try different samples\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     n_tries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:376\u001b[0m, in \u001b[0;36mTuner.runUserObjective\u001b[0;34m(self, X_next_PS)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunUserObjective\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_next_PS):\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# initially assuming entire X_next_PS is evaluated and returned results are only Y values\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     X_list_evaluated \u001b[38;5;241m=\u001b[39m X_next_PS\n\u001b[0;32m--> 376\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next_PS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     Y_list_evaluated \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# if result is a tuple, then there is possibility that partial values are evaluated\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/scheduler.py:30\u001b[0m, in \u001b[0;36mparallel.<locals>.decorator.<locals>.wrapper\u001b[0;34m(params_batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(params_batch):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\u001b[0;31mTypeError\u001b[0m: run_one_training() got an unexpected keyword argument 'model_num_toreduce'"
     ]
    }
   ],
   "source": [
    "print(\"Running hyperparameter search...\")\n",
    "config = dict()\n",
    "config[\"optimizer\"] = \"Bayesian\"\n",
    "config[\"num_iteration\"] = 40\n",
    "\n",
    "\n",
    "tuner = Tuner(HYPERPARAMETERS,\n",
    "              objective=run_one_training,\n",
    "              conf_dict=config) \n",
    "results = tuner.minimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab290ea6-4851-4685-9186-2dafbcd7e501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'model_num_toreduce': 64, 'model_num_ly': 10, 'lr': 0.0001, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "print('best parameters:', results['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa49dd28-7622-4c95-a58b-6159ecf2b280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss (RMSE): 0.14594137528188478\n"
     ]
    }
   ],
   "source": [
    "print('best loss ', results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db214c67-8c96-4eaf-a2c3-546b113a5d31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_params': array([{'model_num_toreduce': 64, 'model_num_ly': 3, 'lr': 0.0001, 'batch_size': 32},\n",
       "        {'model_num_toreduce': 64, 'model_num_ly': 10, 'lr': 0.0001, 'batch_size': 32},\n",
       "        {'model_num_toreduce': 64, 'model_num_ly': 10, 'lr': 0.0001, 'batch_size': 32}],\n",
       "       dtype=object),\n",
       " 'random_params_objective': array([-0.38764714, -0.14594138]),\n",
       " 'params_tried': array([{'model_num_toreduce': 64, 'model_num_ly': 3, 'lr': 0.0001, 'batch_size': 32},\n",
       "        {'model_num_toreduce': 64, 'model_num_ly': 10, 'lr': 0.0001, 'batch_size': 32},\n",
       "        {'batch_size': 32, 'lr': 0.0001, 'model_num_ly': 10, 'model_num_toreduce': 64},\n",
       "        {'batch_size': 32, 'lr': 0.0001, 'model_num_ly': 3, 'model_num_toreduce': 64}],\n",
       "       dtype=object),\n",
       " 'objective_values': array([0.38764714, 0.14594138, 0.15297141, 0.38560471]),\n",
       " 'surrogate_values': array([-0.38764714, -0.14594138,  0.        ,  0.        ]),\n",
       " 'best_objective': 0.14594137528188478,\n",
       " 'best_params': {'model_num_toreduce': 64,\n",
       "  'model_num_ly': 10,\n",
       "  'lr': 0.0001,\n",
       "  'batch_size': 32}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6231e-95c6-4396-9e02-e517a1b439fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Size = 201 \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(30,5))\n",
    "plt.title('Variation of Objective',fontsize=20)\n",
    "plt.plot(results['objective_values'][:Size],lw=4,label='BL')\n",
    "plt.xlabel('Iterations', fontsize=25)\n",
    "plt.ylabel('objective_values',fontsize=25)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68edf67-38ab-4651-8945-79e07bb19204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918bb265-cab3-4db0-bc83-726ffd904f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89357a-a894-41e7-ab13-271de42b9a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815b6ed-d71f-41a2-a544-bcb3e6c25281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2fcabc-3e79-46fd-890c-0ecaad1686c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f9361e26-8f31-44a3-b97d-e4fd2d38f084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# criterion=torch.nn.functional.binary_cross_entropy#for sageconv\n",
    "\n",
    "# def train_model(train_data,model,optimizer):\n",
    "#     model.to(device)\n",
    "#     model.train()\n",
    "#     for data in train_data:\n",
    "       \n",
    "#         data.to(device)\n",
    "#         out = model(data) # Perform a single forward pass.\n",
    "#         labels=data.y.float().to(device)\n",
    "        \n",
    "#         loss = criterion(out.squeeze(1).float(), labels)  # Compute the loss.\n",
    "        \n",
    "#         loss.backward()  # Derive gradients.\n",
    "#         optimizer.step()  # Update parameters based on gradients.\n",
    "#         optimizer.zero_grad()  # Clear gradients.\n",
    "        \n",
    "#     return model.to(device)\n",
    "\n",
    "# threshold=0.8\n",
    "# def evaluate_model(model,test_data):\n",
    "   \n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total_samples = 0\n",
    "#     model_outputs = []\n",
    "#     targets = []\n",
    "#     pred_class=[]\n",
    "\n",
    "#     for data in test_data:\n",
    "#         data.to(device)\n",
    "#         model_output = model(data)\n",
    "#         model_output.to(device)\n",
    "#         predicted_class = torch.where(model_output > threshold, 1, 0)\n",
    "        \n",
    "#         correct += int((predicted_class == data.y.float()).sum())\n",
    "#         total_samples += len(data.y)\n",
    "\n",
    "#           # store these to get the loss\n",
    "#         model_outputs.extend(model_output.tolist())\n",
    "#         targets.extend(data.y.float().tolist())\n",
    "#         pred_class.extend(predicted_class.tolist())\n",
    "\n",
    "    \n",
    "#     loss = criterion(torch.tensor(model_outputs).squeeze(1), torch.tensor(targets).float())\n",
    "#     accuracy = accuracy_score(targets, pred_class)\n",
    "#     precision = precision_score(targets, pred_class)\n",
    "#     recall = recall_score(targets, pred_class)\n",
    "    \n",
    "#     return accuracy, loss, recall, precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d9944a03-6539-4f3d-ade0-b965a7dafa2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=4032,shuffle=True,pin_memory=True,num_workers=15,drop_last=True) \n",
    "# val_loader=DataLoader(val_dataset, batch_size=128,shuffle=True,pin_memory=True,num_workers=15,drop_last=True) \n",
    "# test_loader=DataLoader(test_dataset, batch_size=64,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2447ba62-249b-49ff-92a3-3dcc72d582ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "931842c1-63e5-454b-8fa6-0f6bdce9f6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from mango import scheduler\n",
    "\n",
    "# def objective(param_list):\n",
    "#     param_list=param_list[0]\n",
    "#     print('param_list ',param_list )\n",
    "    \n",
    "#     model_params = {k: v for k, v in param_list.items() if k.startswith(\"model_\")}\n",
    "#     print(model_params)\n",
    "#     hidden_size = model_params['model_num_toreduce'] * model_params['model_num_ly']\n",
    "#     print(model_params['model_num_ly'])\n",
    "#     print(hidden_size)\n",
    "#     print(model_params)\n",
    "#     model = SageConv2(5, hidden_size, num_class, model_params)\n",
    "#     print(model)\n",
    "#     print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "#     model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=param_list['lr'])\n",
    "#     # Addestramento e valutazione\n",
    "#     for epoch in range(1, 2):\n",
    "#         start = time.time()\n",
    "#         model = train_model(train_loader, model, optimizer)\n",
    "#         train_acc, train_loss, _, _ = evaluate_model(model, train_loader)\n",
    "#         val_acc, val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "#     return [train_loss]\n",
    "\n",
    "\n",
    "#         # model = GNN_model.SageConv2(hidden_size, ly, NUM_FEATURES, 1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9dfe25fe-0a07-4908-a367-43bc6a573f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_list  {'model_num_toreduce': 64, 'model_num_ly': 3, 'lr': 0.0001, 'batch_size': 32}\n",
      "{'model_num_toreduce': 64, 'model_num_ly': 3}\n",
      "3\n",
      "192\n",
      "{'model_num_toreduce': 64, 'model_num_ly': 3}\n",
      "SageConv2(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): SAGEConv(5, 192, aggr=mean)\n",
      "    (1): SAGEConv(192, 128, aggr=mean)\n",
      "    (2): SAGEConv(128, 1, aggr=mean)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 51649\n",
      "param_list  {'model_num_toreduce': 64, 'model_num_ly': 10, 'lr': 0.0001, 'batch_size': 32}\n",
      "{'model_num_toreduce': 64, 'model_num_ly': 10}\n",
      "10\n",
      "640\n",
      "{'model_num_toreduce': 64, 'model_num_ly': 10}\n",
      "SageConv2(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): SAGEConv(5, 640, aggr=mean)\n",
      "    (1): SAGEConv(640, 576, aggr=mean)\n",
      "    (2): SAGEConv(576, 512, aggr=mean)\n",
      "    (3): SAGEConv(512, 448, aggr=mean)\n",
      "    (4): SAGEConv(448, 384, aggr=mean)\n",
      "    (5): SAGEConv(384, 320, aggr=mean)\n",
      "    (6): SAGEConv(320, 256, aggr=mean)\n",
      "    (7): SAGEConv(256, 192, aggr=mean)\n",
      "    (8): SAGEConv(192, 128, aggr=mean)\n",
      "    (9): SAGEConv(128, 1, aggr=mean)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 2697089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76d2cf6cd0e4d919a0f898af3481aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_list  {'batch_size': 32, 'lr': 0.0001, 'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "{'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "3\n",
      "192\n",
      "{'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "SageConv2(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): SAGEConv(5, 192, aggr=mean)\n",
      "    (1): SAGEConv(192, 128, aggr=mean)\n",
      "    (2): SAGEConv(128, 1, aggr=mean)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 51649\n",
      "param_list  {'batch_size': 32, 'lr': 0.0001, 'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "{'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "3\n",
      "192\n",
      "{'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "SageConv2(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): SAGEConv(5, 192, aggr=mean)\n",
      "    (1): SAGEConv(192, 128, aggr=mean)\n",
      "    (2): SAGEConv(128, 1, aggr=mean)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 51649\n",
      "param_list  {'batch_size': 32, 'lr': 0.0001, 'model_num_ly': 10, 'model_num_toreduce': 64}\n",
      "{'model_num_ly': 10, 'model_num_toreduce': 64}\n",
      "10\n",
      "640\n",
      "{'model_num_ly': 10, 'model_num_toreduce': 64}\n",
      "SageConv2(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): SAGEConv(5, 640, aggr=mean)\n",
      "    (1): SAGEConv(640, 576, aggr=mean)\n",
      "    (2): SAGEConv(576, 512, aggr=mean)\n",
      "    (3): SAGEConv(512, 448, aggr=mean)\n",
      "    (4): SAGEConv(448, 384, aggr=mean)\n",
      "    (5): SAGEConv(384, 320, aggr=mean)\n",
      "    (6): SAGEConv(320, 256, aggr=mean)\n",
      "    (7): SAGEConv(256, 192, aggr=mean)\n",
      "    (8): SAGEConv(192, 128, aggr=mean)\n",
      "    (9): SAGEConv(128, 1, aggr=mean)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 2697089\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      5\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(HYPERPARAMETERS, \n\u001b[1;32m      6\u001b[0m               objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m      7\u001b[0m               conf_dict\u001b[38;5;241m=\u001b[39mconfig) \n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:160\u001b[0m, in \u001b[0;36mTuner.minimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize_objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:147\u001b[0m, in \u001b[0;36mTuner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_bayesian:\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunBayesianOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_random:\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunRandomOptimizer()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/tuner.py:258\u001b[0m, in \u001b[0;36mTuner.runBayesianOptimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m     X_next_batch \u001b[38;5;241m=\u001b[39m Optimizer\u001b[38;5;241m.\u001b[39mget_next_batch(\n\u001b[1;32m    255\u001b[0m         X_sample, Y_sample, X_domain_np, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstrategy_is_clustering:\n\u001b[0;32m--> 258\u001b[0m     X_next_batch \u001b[38;5;241m=\u001b[39m \u001b[43mOptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_batch_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_domain_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# assume penalty approach\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     X_next_batch \u001b[38;5;241m=\u001b[39m Optimizer\u001b[38;5;241m.\u001b[39mget_next_batch(\n\u001b[1;32m    264\u001b[0m         X_sample, Y_sample, X_domain_np, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mango/optimizer/bayesian_learning.py:227\u001b[0m, in \u001b[0;36mBayesianLearning.get_next_batch_clustering\u001b[0;34m(self, X, Y, X_tries, batch_size)\u001b[0m\n\u001b[1;32m    224\u001b[0m X_temp \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    225\u001b[0m Y_temp \u001b[38;5;241m=\u001b[39m Y\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurrogate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miteration_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    230\u001b[0m Acquition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGet_Upper_Confidence_Bound(X_tries)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1281\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[1;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1281\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 5]"
     ]
    }
   ],
   "source": [
    "# config = dict()\n",
    "# config[\"optimizer\"] = \"Bayesian\"\n",
    "# config[\"num_iteration\"] = 5\n",
    "\n",
    "# tuner = Tuner(HYPERPARAMETERS, \n",
    "#               objective=objective,\n",
    "#               conf_dict=config) \n",
    "# results = tuner.minimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "63ca825e-38a6-40fc-a945-c43ec9fd0a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparameters: {'batch_size': 32, 'lr': 0.0001, 'model_num_ly': 3, 'model_num_toreduce': 64}\n",
      "best objective: 0.6807309985160828\n"
     ]
    }
   ],
   "source": [
    "print('best hyperparameters:',results['best_params'])\n",
    "print('best objective:',results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000632e-48dd-4185-9c0a-f8fa6f06a36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Iperparametri da sperimentare\n",
    "# learning_rates = [5e-5,1e-4]\n",
    "# # num_heads_list = [4,8,16]\n",
    "# activation1=['tanh']\n",
    "# agg=['max','sum']\n",
    "# best_val_loss = float('inf')\n",
    "# best_params = None\n",
    "# num_ly_list=[3,5,10]\n",
    "# for lr,act1,ly in itertools.product(learning_rates,activation1,num_ly_list):\n",
    "#     start = time.time()\n",
    "#     print('ly ',ly)\n",
    "#     hidden_size = 64*ly\n",
    "#     # model = SageConv(num_feat,num_class,aggr)\n",
    "#     model = GNN_model.SageConv2(hidden_size, ly, NUM_FEATURES, 1,64)\n",
    "#     model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     reset_weights(model)\n",
    "#     # Addestramento e valutazione\n",
    "#     for epoch in range(1, 2):\n",
    "#         start = time.time()\n",
    "#         model = train_model(train_loader)\n",
    "#         train_acc, train_loss,_, _ = evaluate_model(model, train_loader)\n",
    "#         val_acc, val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "#         if epoch % 1 == 0:\n",
    "           \n",
    "#             print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss:.4f}, time :{time.time() - start} ')\n",
    "\n",
    "#         if val_loss.item() <= best_val_loss:\n",
    "#             best_val_loss = val_loss.item()\n",
    "            \n",
    "#             best_params = {\n",
    "#                 'learning_rate': lr,\n",
    "#                 'hidden_layer_size': hidden_size,\n",
    "#                 'activation1':act1,\n",
    "#                 'numly':ly\n",
    "#             }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dde8bfaf-fa05-4623-a990-fc0f991b2e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def reset_weights(m):\n",
    "#     if isinstance(m, SAGEConv) or isinstance(m,Linear):\n",
    "#         m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab520107-f88d-4f28-8fe9-90c04bf342e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilizza i migliori parametri trovati\n",
    "# best_model = SageConv(num_feat,num_class,aggr=best_params['aggregation'])\n",
    "# best_model.to(device)\n",
    "# optimizer = torch.optim.Adam(best_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c7f1450-a43a-40d0-8e7a-b0c251d27c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Iperparametri da sperimentare\n",
    "# learning_rates = [0.0001]\n",
    "# hidden_layer_sizes = [256]\n",
    "# # num_heads_list = [4,8,16]\n",
    "# activation1=['tanh']\n",
    "# agg=['mean','sum','lstm']\n",
    "# best_val_loss = float('inf')\n",
    "# best_params = None\n",
    "\n",
    "# for lr, hidden_size,act1,act2 in itertools.product(learning_rates, hidden_layer_sizes,activation1,agg):\n",
    "#     start = time.time()\n",
    "#     model = SageConv(hidden_size,act1,act2)\n",
    "#     model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     reset_weights(model)\n",
    "#     # Addestramento e valutazione\n",
    "#     for epoch in range(1, 100):\n",
    "#         model = train_model(train_loader)\n",
    "#         train_acc, train_loss,_, _ = evaluate_model(model, train_loader)\n",
    "#         val_acc, val_loss, _, _ = evaluate_model(model, val_loader)\n",
    "#         if epoch % 1 == 0:\n",
    "#             print(f'lr: {lr},hidden_size: {hidden_size}, act1: {act1}, aggregation: {act2}')\n",
    "#             print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss:.4f}, time :{time.time() - start} ')\n",
    "\n",
    "#         if val_loss.item() <= best_val_loss:\n",
    "#             best_val_loss = val_loss.item()\n",
    "#             print('BEST lr ',lr,' hidden ',hidden_size,' act ',act1,' aggr ',act2 )\n",
    "#             best_params = {\n",
    "#                 'learning_rate': lr,\n",
    "#                 'hidden_layer_size': hidden_size,\n",
    "#                 'activation1':act1,\n",
    "#                 'aggregation':act2\n",
    "#             }\n",
    "            \n",
    "\n",
    "# # Utilizza i migliori parametri trovati\n",
    "# best_model = SageConv(best_params['hidden_layer_size'],best_params['activation1'],best_params['activation2'])\n",
    "# best_model.to(device)\n",
    "# optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ce02f6-1a55-4aee-b955-89d757658137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aggregation': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b553847-6771-40f5-91b4-49beedc09fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_stop: 1\n",
      "Epoch: 1, Train Acc: 0.5038, Train Loss: 0.4718, Val Acc: 0.5026, Val Loss: 0.4693\n"
     ]
    }
   ],
   "source": [
    "# # Addestramento e valutazione finale\n",
    "# train_accuracies = []\n",
    "# validation_accuracies = []\n",
    "# validation_losses = []\n",
    "# train_losses = []\n",
    "\n",
    "# val_recall=[]\n",
    "# val_precision=[]\n",
    "# train_recall=[]\n",
    "# train_precision=[]\n",
    "\n",
    "# for epoch in range(1, 200):\n",
    "#     best_model = train_model(train_loader)\n",
    "#     train_acc, train_loss, train_rec, train_prec = evaluate_model(best_model, train_loader)\n",
    "#     val_acc, val_loss, val_rec, val_prec = evaluate_model(best_model, val_loader)\n",
    "#     train_losses.append(train_loss)\n",
    "                   \n",
    "#     validation_losses.append(val_loss)\n",
    "\n",
    "#     train_accuracies.append(train_acc)\n",
    "#     validation_accuracies.append(val_acc)\n",
    "    \n",
    "#     train_precision.append(train_prec)\n",
    "#     train_recall.append(train_rec)\n",
    "    \n",
    "#     val_precision.append(val_prec)\n",
    "#     val_recall.append(val_rec)\n",
    "#     if val_loss.item() <= min(validation_losses).item():\n",
    "#         torch.save(model, f'/lustrehome/federicacuna/TB_Sept_2023_ml/output_gnn_pkl/1mill_ev_200epoch_hyp/best_model_GCNHYP.pkl')\n",
    "#         print(f'Epoch_stop: {epoch}')\n",
    "\n",
    "#     if epoch % 20 == 0:\n",
    "#         print(f'Epoch: {epoch}, Train Acc: {train_acc:.4f}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e5d40aa-32af-4f5e-82ae-1d049c1d9ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best result was achieved after 0 epochs with a validation accuracy of 0.5026 and a loss of 0.4693\n",
      "The validation recall is 0.2694 and the precision is 0.9843\n"
     ]
    }
   ],
   "source": [
    "# best_validation_loss = min(validation_losses)\n",
    "# best_epoch = validation_losses.index(best_validation_loss)\n",
    "# accuracy_at_best_epoch = validation_accuracies[best_epoch]\n",
    "# recall_at_best_epoch=val_recall[best_epoch]\n",
    "# precision_at_best_epoch=val_precision[best_epoch]\n",
    "# print(f\"The best result was achieved after {best_epoch} epochs with a validation accuracy of {accuracy_at_best_epoch:.4f} and a loss of {best_validation_loss:.4f}\")\n",
    "# print(f\"The validation recall is {recall_at_best_epoch:.4f} and the precision is {precision_at_best_epoch:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a94fe7c-1f20-4173-90ef-812b0f01e770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# #fig.set_size_inches(30.5, 15.5)\n",
    "\n",
    "# plt.plot(validation_losses,color='orange',label='validation loss')\n",
    "# plt.plot(train_losses,color='blue',label='training loss')\n",
    "\n",
    "# plt.axvline(x=best_epoch, color=\"green\", linewidth=2, linestyle='dashed',label='best epoch')\n",
    "# #plt.legend(['Val Loss', 'Train Loss', \"Best Epoch\"])\n",
    "# plt.legend()\n",
    "\n",
    "# # Hide the right and top spines\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['bottom'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "\n",
    "# plt.title(\"Model training and validation loss per epoch\", fontsize=10, fontweight='bold')\n",
    "# #plt.ylim(0.05,0.2)\n",
    "# plt.savefig('/lustrehome/federicacuna/TB_Sept_2023_ml/output_gnn_img/1million_sageconv_hyp/GCNHYP_loss.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61d70c32-f00c-4af8-833b-13e8a256cba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# #fig.set_size_inches(30.5, 15.5)\n",
    "\n",
    "# plt.plot(validation_accuracies,color='orange',label='validation acc')\n",
    "# plt.plot(train_accuracies,color='blue',label='training acc')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# # Hide the right and top spines\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['bottom'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "\n",
    "# plt.title(\"Model training and validation accuracy per epoch\", fontsize=10, fontweight='bold')\n",
    "# #plt.ylim(0.05,0.2)\n",
    "# plt.savefig('/lustrehome/federicacuna/TB_Sept_2023_ml/output_gnn_img/1million_sageconv_hyp/GCNHYP_acc.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07d4ac14-2b1e-4912-b8c6-c7b9d1a8960c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.5023663157894737  recall  0.26915799432355725  precision  0.982550213578115\n"
     ]
    }
   ],
   "source": [
    "# best_model = torch.load(\"/lustrehome/federicacuna/TB_Sept_2023_ml/output_gnn_pkl/1mill_ev_200epoch_hyp/best_model_sageconv4ly.pkl\")\n",
    "# best_model.to(device) \n",
    "\n",
    "# correct = 0\n",
    "# total_samples = 0\n",
    "# pred_test_cl=[]\n",
    "# targets=[]\n",
    "# with torch.no_grad():\n",
    "#     for data in test_loader:\n",
    "#         data = data.to(device)  \n",
    "        \n",
    "#         model_output = best_model(data)\n",
    "#         predicted_class =  torch.where(model_output > 0.8, 1, 0)\n",
    "#         pred_test_cl.extend(predicted_class.tolist())\n",
    "#         correct += int((predicted_class == data.y).sum())\n",
    "#         targets.extend(data.y.tolist())\n",
    "#         total_samples += data.y.size(0)\n",
    "\n",
    "# print('accuracy ',accuracy_score(targets,pred_test_cl),' recall ', recall_score(targets,pred_test_cl),' precision ',precision_score(targets,pred_test_cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af51372-f2f0-4fcd-a3fd-778d58fd7aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
